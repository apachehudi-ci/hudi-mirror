{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36835b8e-37cb-4c86-ad7f-c0322ffcd7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Licensed to the Apache Software Foundation (ASF) under one\n",
    "#  or more contributor license agreements.  See the NOTICE file\n",
    "#  distributed with this work for additional information\n",
    "#  regarding copyright ownership.  The ASF licenses this file\n",
    "#  to you under the Apache License, Version 2.0 (the\n",
    "#  \"License\"); you may not use this file except in compliance\n",
    "#  with the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2c4b5-2645-453f-8ae5-8475becdf620",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://hudi.apache.org/assets/images/hudi-logo-medium.png\" alt=\"Hudi logo\" width=\"100%\" height=\"320\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d03aa-5387-4a55-aa10-a5fc2511ad5e",
   "metadata": {},
   "source": [
    "# Querying Hudi Tables using Trino: A Step-by-Step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa84d4-0ad7-47d0-a9ec-38d7059679c6",
   "metadata": {},
   "source": [
    "This guide demonstrates a cross-engine workflow: writing optimized Lakehouse tables with Apache Spark and querying them with Trino for fast, interactive analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4ce1c-0342-4f6c-a296-864a0311ef6e",
   "metadata": {},
   "source": [
    "### 1. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae14e01-3fb0-4fb8-be7d-9e8520df2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import trino.dbapi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e41c4c-8f59-470f-bcca-12b6cf9b4ac0",
   "metadata": {},
   "source": [
    "### 2. Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a448fc-39a5-4082-be72-eb73f1e77cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"trino_db\"\n",
    "table_name = \"hudi_trips_table\"\n",
    "s3_base_path = f\"s3a://warehouse/\"\n",
    "base_path = os.path.join(s3_base_path, db_name, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0add876-ce06-4377-ac8d-60a3b4968921",
   "metadata": {},
   "source": [
    "### 3. Spark Session Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb5c7b-6d2e-458f-92df-70befc8edba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec9d7c-7fe7-40d0-876b-60c633af93ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark_session(app_name = \"Hudi Trino Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d519af-aee1-4f66-b2ba-801ce73587e1",
   "metadata": {},
   "source": [
    "### 4. Sample Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc1bbf-7106-4442-8d5a-ac7b6f5f9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ts\", \"uuid\", \"rider\", \"driver\", \"fare\", \"city\"]\n",
    "\n",
    "data = [\n",
    "    (\"2025-08-10 08:15:30\", \"uuid-001\", \"rider-A\", \"driver-X\", 18.50, \"new_york\"),\n",
    "    (\"2025-08-10 09:22:10\", \"uuid-002\", \"rider-B\", \"driver-Y\", 22.75, \"san_francisco\"),\n",
    "    (\"2025-08-10 10:05:45\", \"uuid-003\", \"rider-C\", \"driver-Z\", 14.60, \"chicago\"),\n",
    "    (\"2025-08-10 11:40:00\", \"uuid-004\", \"rider-D\", \"driver-W\", 31.90, \"new_york\"),\n",
    "    (\"2025-08-10 12:55:15\", \"uuid-005\", \"rider-E\", \"driver-V\", 25.10, \"san_francisco\"),\n",
    "    (\"2025-08-10 13:20:35\", \"uuid-006\", \"rider-F\", \"driver-U\", 19.80, \"chicago\"),\n",
    "    (\"2025-08-10 14:10:05\", \"uuid-007\", \"rider-G\", \"driver-T\", 28.45, \"san_francisco\"),\n",
    "    (\"2025-08-10 15:00:20\", \"uuid-008\", \"rider-H\", \"driver-S\", 16.25, \"new_york\"),\n",
    "    (\"2025-08-10 15:45:50\", \"uuid-009\", \"rider-I\", \"driver-R\", 24.35, \"chicago\"),\n",
    "    (\"2025-08-10 16:30:00\", \"uuid-010\", \"rider-J\", \"driver-Q\", 20.00, \"new_york\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e34d17-66ab-492b-953c-dd8a30392ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = spark.createDataFrame(data).toDF(*columns)\n",
    "display(input_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e9aa4-cc2b-4af8-9c1d-11f186ca4954",
   "metadata": {},
   "source": [
    "### 5. Hudi Write Configuration & Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca967e-cbf2-417d-b0d9-215b800dee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hudi_write_options = {\n",
    "    \"hoodie.table.name\" : table_name,\n",
    "    \"hoodie.datasource.write.recordkey.field\": \"uuid\",\n",
    "    \"hoodie.datasource.write.precombine.field\": \"ts\",\n",
    "    \"hoodie.datasource.write.partitionpath.field\": \"city\",\n",
    "    \"hoodie.metadata.enable\": \"true\",\n",
    "    \"hoodie.datasource.write.hive_style_partitioning\": \"true\",\n",
    "    \"hoodie.datasource.meta.sync.enable\": \"true\",\n",
    "    \"hoodie.datasource.hive_sync.partition_fields\": \"city\",\n",
    "    \"hoodie.datasource.hive_sync.mode\": \"hms\",\n",
    "    \"hoodie.datasource.hive_sync.metastore.uris\": \"thrift://hive-metastore:9083\",\n",
    "    \"hoodie.datasource.hive_sync.database\": db_name,\n",
    "    \"hoodie.datasource.hive_sync.table\": table_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62958ce-d753-478a-ad40-a6850273144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to Hudi\n",
    "input_df.write.format(\"hudi\") \\\n",
    "    .options(**hudi_write_options) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01c17e-023b-4ff2-8e02-4fd57c50fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"SELECT * FROM {db_name}.{table_name}\")\n",
    "display(df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7226027-2b03-4b68-be4c-f6194a26f6b1",
   "metadata": {},
   "source": [
    "### 6. Querying with Trino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b97899-19f3-4662-a98f-28ec7c04354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Trino Connection\n",
    "TRINO_HOST='trino'\n",
    "TRINO_PORT=8080\n",
    "TRINO_CATALOG='hudi'\n",
    "TRINO_SCHEMA=db_name\n",
    "\n",
    "conn = trino.dbapi.connect(\n",
    "    host=TRINO_HOST,\n",
    "    port=TRINO_PORT,\n",
    "    user='trino',            \n",
    "    catalog=TRINO_CATALOG,\n",
    "    schema=TRINO_SCHEMA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c5e2d-83a6-4ed7-a894-f26af7e02ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the Data from Trino\n",
    "try:\n",
    "    query = f\"SELECT * FROM {table_name} LIMIT 100\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    pandas_df = pd.DataFrame(rows, columns=colnames)\n",
    "finally:\n",
    "    cur.close()\n",
    "\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "display(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c683b-cbb3-4149-81ab-b4d8df7a2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Trino Connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912d31b-aeef-40f1-86e3-49f26c9f415c",
   "metadata": {},
   "source": [
    "### 7. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc0033-5043-4858-a053-f41afb833cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark Session\n",
    "stop_spark_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
